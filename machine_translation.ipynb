{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Machine Translation Using a Seq2Seq Architecture\n",
        "Â© 2023, Zaka AI, Inc. All Rights Reserved.\n",
        "\n",
        "---\n",
        "The goal of this colab is to get you more familiar with the Seq2Seq models and their challenges. For this reason, you will be working on machine translation problem where we would have a sentence as input (in english), and the output is gonna be the translated sentence (in french). So just like what happens with Google Translate.\n"
      ],
      "metadata": {
        "id": "xiC75uo6u_Of"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Just to give you a heads up:** We won't be having a model performing like Google translate, but at least we will have an idea about how Google Translate works and the challenges that exist with a translation problem.  "
      ],
      "metadata": {
        "id": "TeK4LPupvg_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "SBTvDTzBv293"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by importing numpy and pandas and then we can add the rest"
      ],
      "metadata": {
        "id": "4_j1ZzS3v6N3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n0IARXAX1e1m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import random\n",
        "from keras.models import Model\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import ne_chunk, pos_tag, word_tokenize\n",
        "from nltk.tree import Tree\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from keras.optimizers import Adam, Adadelta, Adamax\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.layers import Embedding, Bidirectional, Dot, Softmax, Input, GRU, Dense, Dropout, Concatenate, Attention, LSTM, TimeDistributed, RepeatVector\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiKCtU2QXidS",
        "outputId": "97a9fc94-6cbd-4c67-d13f-8fbe2df8c2c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We clone the github repository where our data exists. Here is the github link: https://github.com/zaka-ai/machine_learning_certification/tree/main/Challenge%207 "
      ],
      "metadata": {
        "id": "vAcLqZ7uv-SJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the data"
      ],
      "metadata": {
        "id": "i3hLN42axOjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Your Zaka\n",
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/zaka-ai/machine_learning_certification.git"
      ],
      "metadata": {
        "id": "0-M7cFxTPpqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e81fa5-7982-49bd-8905-2f342491cbc3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'machine_learning_certification'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 43 (delta 10), reused 10 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (43/43), 43.23 MiB | 9.59 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We read the english sentences in a dataframe named \"english\", and the french sentences in a dataframe named \"french\""
      ],
      "metadata": {
        "id": "BaPr0N8cwGAv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kFj8gkP01lGT"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka (English)\n",
        "english = pd.read_csv('machine_learning_certification/Challenge 7/en.csv', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "P4A7ZKt32A7s"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka (French)\n",
        "french = pd.read_csv('machine_learning_certification/Challenge 7/fr.csv', header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How many sentences does each of the files contain?**"
      ],
      "metadata": {
        "id": "jr8OO1OhwSp4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XhWJP-b02HKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3575dfd-4e4d-45ae-975e-e9035a812865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of English sentences: 137860\n",
            "Number of French sentences: 137860\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "en_sentences = len(english)\n",
        "fr_sentences = len(french)\n",
        "print(\"Number of English sentences:\", en_sentences)\n",
        "print(\"Number of French sentences:\", fr_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us concatenate the 2 dataframes into one dataframe that we call **df** where one column has the english senetnces and the other has the french sentences"
      ],
      "metadata": {
        "id": "ITGJN5tIwkDO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-ZXxahsB2njn"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "# Concatenate the English and French dataframes into a single dataframe called \"df\"\n",
        "df = pd.concat([english, french], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's name the columns as **English** and **French** so that we access them easier."
      ],
      "metadata": {
        "id": "nAr_caXkwwE7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eOHiQDXx3jFS"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "df.columns = ['English', 'French']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pick a sentence and print it in both languages"
      ],
      "metadata": {
        "id": "4xc1TsEHw9yC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QuRVWch23ujo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48e023a9-e353-4aa2-8190-7ab567760f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Sentence: he plans to visit china in march .\n",
            "\n",
            "French Sentence: il envisage de se rendre en chine en mars .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "# Select a random sentence index\n",
        "idx = random.randint(0, len(df)-1)\n",
        "# Print the corresponding English and French sentences\n",
        "print('English Sentence: {}\\n'.format(df['English'][idx]))\n",
        "print('French Sentence: {}\\n'.format(df['French'][idx]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cleaning Data"
      ],
      "metadata": {
        "id": "FQjXYP1txFCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data that we have is almost clean as we can see, we just need to remove the punctuations inside of it."
      ],
      "metadata": {
        "id": "xgz6jIoVxHUF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6YYOt5QftcFI"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "def remove_punctuations(sentence):\n",
        "    # Create a string with all the punctuations to remove\n",
        "    punctuations = string.punctuation\n",
        "    # Create a translation table to remove the punctuations from the sentence\n",
        "    translator = str.maketrans('', '', punctuations)\n",
        "    # Remove the punctuations from the sentence using the translation table\n",
        "    sentence = sentence.translate(translator)\n",
        "    return sentence\n",
        "df['english'] = df['English'].apply(remove_punctuations)\n",
        "df['french'] = df['French'].apply(remove_punctuations)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure that the punctuation is removed by printing the example that you printed earlier."
      ],
      "metadata": {
        "id": "0C1qsC9LxZPb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "T80tiWxe84G7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7609ae-00fe-4c1b-8b4b-47e8441abf23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original English sentence:  he plans to visit china in march .\n",
            "\n",
            "Cleaned English sentence:  he plans to visit china in march \n",
            "\n",
            "Original French sentence:  il envisage de se rendre en chine en mars .\n",
            "\n",
            "Cleaned French sentence:  il envisage de se rendre en chine en mars  \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "print(\"Original English sentence: \", df['English'][idx]+'\\n')\n",
        "print(\"Cleaned English sentence: \", remove_punctuations(df['English'][idx] +'\\n'))\n",
        "\n",
        "print(\"Original French sentence: \", df['French'][idx]+'\\n')\n",
        "print(\"Cleaned French sentence: \", remove_punctuations(df['French'][idx]),'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exploring the Data"
      ],
      "metadata": {
        "id": "ZuFNjoBAx4oN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a column **ENG Length** to the dataset that shows how many words does a sentence contain, and do the same for french in a column called **FR Length**"
      ],
      "metadata": {
        "id": "ATfefzPExi2k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Dakeo81s352S"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "# Add columns for ENG Length and FR Length\n",
        "df['ENG Length'] = df['english'].apply(lambda x: len(x.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "49keasjaPaaK"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "# Add columns for ENG Length and FR Length\n",
        "df['FR Length'] = df['french'].apply(lambda x: len(x.split()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the distribution of the lengths of english sentences and french sentences."
      ],
      "metadata": {
        "id": "AjQLW0K5xwx1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_q_UIMJ09L24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "50fbaefd-91f7-4ca7-9f4d-133bd2160269"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Frequency')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "# Create a figure with two subplots\n",
        "fig, axs = plt.subplots(1, figsize=(12, 5))\n",
        "\n",
        "# Plot the distribution of English sentence lengths\n",
        "axs.hist(df['ENG Length'], bins=50, color='blue')\n",
        "axs.set_xlabel('Length of English sentences')\n",
        "axs.set_ylabel('Frequency')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TSn4L7kW9R7g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "1f88673b-9beb-44c0-f622-83020ca83209"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "fig, axs = plt.subplots(1, figsize=(12, 5))\n",
        "# Plot the distribution of French sentence lengths\n",
        "axs.hist(df['FR Length'], bins=50, color='red')\n",
        "axs.set_xlabel('Length of French sentences')\n",
        "axs.set_ylabel('Frequency')\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the maximum length of an english sentence and the maximum length of a french sentence. "
      ],
      "metadata": {
        "id": "BDXb2d9ix9DV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BpnBB04U_lHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03b8d13b-408d-4824-ea00-1b74e05c8ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15 21\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "max_eng_length = df['ENG Length'].max()\n",
        "max_fr_length = df['FR Length'].max()\n",
        "print(max_eng_length, max_fr_length)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the stop words to be removed\n",
        "stop_words = set(stopwords.words('english'))\n",
        "# Define the stop words to be removed\n",
        "stop_words = set(stopwords.words('french'))\n",
        "def apply_lemmatization(sentence):\n",
        "    # Tokenize the sentence into wordsa\n",
        "    words = word_tokenize(sentence)\n",
        "    # Initialize the WordNetLemmatizer for English language\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    # Apply lemmatization on each word in the sentence\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    # Join the lemmatized words into a sentence\n",
        "    lemmatized_sentence = \" \".join(lemmatized_words)\n",
        "    return lemmatized_sentence\n",
        "    \n",
        "df['english'] = df['english'].apply(apply_lemmatization)\n",
        "df['french'] = df['french'].apply(apply_lemmatization)\n"
      ],
      "metadata": {
        "id": "rAnZi0sU1Pd2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing the Data"
      ],
      "metadata": {
        "id": "s4s-spsRyGJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order for the data to be fed to the model, it has to be tokenized and padded. "
      ],
      "metadata": {
        "id": "N0ZmIT2GyJMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Tokenization"
      ],
      "metadata": {
        "id": "R0r9z-eErm9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To tokenize english and french sentences, we can use only one tokenizer. True or False?**"
      ],
      "metadata": {
        "id": "X5L_zkhfyQuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[False]"
      ],
      "metadata": {
        "id": "1Z0ZcNOeyauD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the sentences that we have."
      ],
      "metadata": {
        "id": "814mKDFiymcY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "aiXlciqFuQzW"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "# Tokenize the English sentences\n",
        "eng_tokenizer = Tokenizer()\n",
        "eng_tokenizer.fit_on_texts(df['english'])\n",
        "eng_sequences = eng_tokenizer.texts_to_sequences(df['english'])\n",
        "\n",
        "# Tokenize the French sentences\n",
        "fr_tokenizer = Tokenizer()\n",
        "fr_tokenizer.fit_on_texts(df['french'])\n",
        "fr_sequences = fr_tokenizer.texts_to_sequences(df['french'])\n",
        "# Find the number of unique words in the English sentences\n",
        "num_eng_words = len(eng_tokenizer.word_index)+1\n",
        "num_fr_words = len(fr_tokenizer.word_index)+1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How many unique words do we have in english and in french?**"
      ],
      "metadata": {
        "id": "aUN01jDXys9B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1WahkdzKvIlO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3932052-1320-4522-fc51-ced353abbbd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words in English sentences: 171\n",
            "Number of unique words in French sentences: 331\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "# Find the number of unique words in the English sentences\n",
        "num_eng_words = len(eng_tokenizer.word_index)+1\n",
        "print(\"Number of unique words in English sentences:\", num_eng_words)\n",
        "\n",
        "# Find the number of unique words in the French sentences\n",
        "num_fr_words = len(fr_tokenizer.word_index)+1\n",
        "print(\"Number of unique words in French sentences:\", num_fr_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Padding"
      ],
      "metadata": {
        "id": "g0C2RJjArtJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What should be the length of the sequences that we have after padding?**"
      ],
      "metadata": {
        "id": "vXdTXMo5y8oB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the length of the sequences after padding should be for english 15 and 21 for french we will choose 21 as threshold to be the fixed length to work with"
      ],
      "metadata": {
        "id": "9wtHQsgXzImq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform padding on the sequences that we have."
      ],
      "metadata": {
        "id": "hRXayRzVzQD4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oNdO9EZrxvmN"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "fixed_length = 21\n",
        "# Perform padding on English sequences\n",
        "eng_padded_sequences = pad_sequences(eng_sequences, maxlen=fixed_length , padding='post')\n",
        "# Perform padding on French sequences\n",
        "fr_padded_sequences = pad_sequences(fr_sequences, maxlen=fixed_length , padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and test sets (80% training, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(eng_padded_sequences, fr_padded_sequences, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the training set into training and validation sets (90% training, 10% validation)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "0Kr42kKKcQkw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modeling"
      ],
      "metadata": {
        "id": "JxvvVU3ezUHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After preprrocessing the data, we can build our model. Start by building a baseline architecture relying on one directional RNNs, LSTMs, or GRUs. It will be good to lookup how to build Seq2Seq models, there are some new layers that will help you like RepeatVector and TimeDistributed."
      ],
      "metadata": {
        "id": "FEKujJUEzVux"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9oydzHkr3zDC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92205993-278f-409c-ba15-798f10b0b597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 21, 64)            10944     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 21, 512)           1181696   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 21, 256)           131328    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 21, 256)           525312    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 21, 128)           197120    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 21, 256)           33024     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 21, 512)           1574912   \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 21, 331)          169803    \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,824,139\n",
            "Trainable params: 3,824,139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_eng_words, 64, input_length=fixed_length))\n",
        "model.add(LSTM(512, return_sequences=True))\n",
        "model.add(Dense(256))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dense(256, activation='softmax'))\n",
        "model.add(LSTM(512, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(num_fr_words, activation='softmax')))\n",
        "\n",
        "# Add early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True)\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile and train the model. \n",
        "**FYI:** While specifying the architecture of your model and the number of epochs for training, keeep in your mind that your model might take A LOT of time to train."
      ],
      "metadata": {
        "id": "aP10HtNBzpT0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lWw4nBNIFp9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26456fbc-7344-419b-e9b3-613b0cf96fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1551/1551 [==============================] - 55s 27ms/step - loss: 1.4906 - accuracy: 0.6174 - val_loss: 0.9766 - val_accuracy: 0.7029\n",
            "Epoch 2/50\n",
            "1551/1551 [==============================] - 31s 20ms/step - loss: 0.8546 - accuracy: 0.7309 - val_loss: 0.7291 - val_accuracy: 0.7662\n",
            "Epoch 3/50\n",
            "1551/1551 [==============================] - 32s 21ms/step - loss: 0.6418 - accuracy: 0.7915 - val_loss: 0.5478 - val_accuracy: 0.8192\n",
            "Epoch 4/50\n",
            "1551/1551 [==============================] - 38s 25ms/step - loss: 0.4830 - accuracy: 0.8442 - val_loss: 0.4099 - val_accuracy: 0.8699\n",
            "Epoch 5/50\n",
            "1551/1551 [==============================] - 33s 21ms/step - loss: 0.3632 - accuracy: 0.8859 - val_loss: 0.3284 - val_accuracy: 0.8955\n",
            "Epoch 6/50\n",
            "1551/1551 [==============================] - 32s 21ms/step - loss: 0.3066 - accuracy: 0.9013 - val_loss: 0.2956 - val_accuracy: 0.9051\n",
            "Epoch 7/50\n",
            "1551/1551 [==============================] - 32s 20ms/step - loss: 0.2757 - accuracy: 0.9090 - val_loss: 0.2667 - val_accuracy: 0.9122\n",
            "Epoch 8/50\n",
            "1551/1551 [==============================] - 33s 21ms/step - loss: 0.2583 - accuracy: 0.9131 - val_loss: 0.2591 - val_accuracy: 0.9137\n",
            "Epoch 9/50\n",
            "1551/1551 [==============================] - 33s 21ms/step - loss: 0.2466 - accuracy: 0.9160 - val_loss: 0.2474 - val_accuracy: 0.9166\n",
            "Epoch 10/50\n",
            "1551/1551 [==============================] - 35s 22ms/step - loss: 0.2370 - accuracy: 0.9184 - val_loss: 0.2587 - val_accuracy: 0.9124\n",
            "Epoch 11/50\n",
            "1551/1551 [==============================] - 34s 22ms/step - loss: 0.2290 - accuracy: 0.9205 - val_loss: 0.2357 - val_accuracy: 0.9193\n",
            "Epoch 12/50\n",
            "1551/1551 [==============================] - 31s 20ms/step - loss: 0.2237 - accuracy: 0.9221 - val_loss: 0.2292 - val_accuracy: 0.9218\n",
            "Epoch 13/50\n",
            "1551/1551 [==============================] - 32s 21ms/step - loss: 0.2191 - accuracy: 0.9230 - val_loss: 0.2278 - val_accuracy: 0.9222\n",
            "Epoch 14/50\n",
            "1551/1551 [==============================] - 31s 20ms/step - loss: 0.2123 - accuracy: 0.9248 - val_loss: 0.2278 - val_accuracy: 0.9215\n",
            "Epoch 15/50\n",
            "1551/1551 [==============================] - 31s 20ms/step - loss: 0.2090 - accuracy: 0.9255 - val_loss: 0.2262 - val_accuracy: 0.9222\n",
            "Epoch 16/50\n",
            "1551/1551 [==============================] - 31s 20ms/step - loss: 0.2118 - accuracy: 0.9248 - val_loss: 0.2223 - val_accuracy: 0.9227\n",
            "Epoch 17/50\n",
            "1551/1551 [==============================] - 31s 20ms/step - loss: 0.2010 - accuracy: 0.9278 - val_loss: 0.2220 - val_accuracy: 0.9243\n",
            "Epoch 18/50\n",
            "1551/1551 [==============================] - 32s 20ms/step - loss: 0.2023 - accuracy: 0.9272 - val_loss: 0.2220 - val_accuracy: 0.9234\n",
            "Epoch 19/50\n",
            "1551/1551 [==============================] - 32s 21ms/step - loss: 0.1988 - accuracy: 0.9282 - val_loss: 0.2172 - val_accuracy: 0.9250\n",
            "Epoch 20/50\n",
            "1551/1551 [==============================] - 31s 20ms/step - loss: 0.1981 - accuracy: 0.9284 - val_loss: 0.2193 - val_accuracy: 0.9244\n",
            "Epoch 21/50\n",
            "1551/1551 [==============================] - 31s 20ms/step - loss: 0.1954 - accuracy: 0.9290 - val_loss: 0.2255 - val_accuracy: 0.9224\n",
            "Epoch 22/50\n",
            "1551/1551 [==============================] - 32s 21ms/step - loss: 0.1938 - accuracy: 0.9295 - val_loss: 0.2189 - val_accuracy: 0.9249\n",
            "Epoch 23/50\n",
            "1551/1551 [==============================] - 31s 20ms/step - loss: 0.1921 - accuracy: 0.9300 - val_loss: 0.2271 - val_accuracy: 0.9226\n",
            "Epoch 24/50\n",
            "1551/1551 [==============================] - 31s 20ms/step - loss: 0.1902 - accuracy: 0.9304 - val_loss: 0.2195 - val_accuracy: 0.9253\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=64, callbacks=[early_stop])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function that gets an input sentence in english and gives the output sentence in the french language."
      ],
      "metadata": {
        "id": "9UoEcxyJztiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Your Zaka\n",
        "def translate_to_french(input_sentence):\n",
        "    # Convert the input sentence to a sequence of integers using the English tokenizer\n",
        "    input_seq = eng_tokenizer.texts_to_sequences([input_sentence])[0]\n",
        "    # Pad the input sequence\n",
        "    input_padded = pad_sequences([input_seq], maxlen=fixed_length, padding='post')\n",
        "    # Use the trained model to generate the output sequence\n",
        "    output_seq = model.predict(input_padded)[0]\n",
        "    # Convert the output sequence to a sequence of integers\n",
        "    output_seq = np.argmax(output_seq, axis=-1)\n",
        "    # Convert the output sequence to a sentence using the French tokenizer\n",
        "    output_sentence = fr_tokenizer.sequences_to_texts([output_seq])[0]\n",
        "    # Remove the padding token from the output sentence\n",
        "    output_sentence = output_sentence.replace('<pad>', '').strip()\n",
        "    return output_sentence"
      ],
      "metadata": {
        "id": "fUU_RdCxYpM6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the following sentence"
      ],
      "metadata": {
        "id": "XUQIcAjWz3bt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "fDmNqnZIQMko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c7acf32-90a3-473a-9bcc-244190d09ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "she is driving the truck : \n",
            "elle conduit cette grande camion brillant\n"
          ]
        }
      ],
      "source": [
        "input = \"she is driving the truck\"\n",
        "\n",
        "#Test Your Zaka\n",
        "predicted_french_sentence = translate_to_french(input)\n",
        "print(input + ' : \\n' +predicted_french_sentence)  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to improve your model by modifying the architecture to take into account bidirectionality which is very useful in Machine Translation. Create a new model called model2"
      ],
      "metadata": {
        "id": "wdI2XhaBz6CN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Ch28BLsbGnCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2aec4a2-68e0-4301-91ba-cbeb73cc82de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 21, 64)            10944     \n",
            "                                                                 \n",
            " bidirectional_16 (Bidirecti  (None, 21, 1024)         2363392   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_17 (Bidirecti  (None, 21, 512)          2623488   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_18 (Bidirecti  (None, 21, 256)          656384    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_19 (Bidirecti  (None, 21, 1024)         3149824   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, 21, 331)          339275    \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,143,307\n",
            "Trainable params: 9,143,307\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "# Define the model architecture\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(num_eng_words, 64, input_length=fixed_length))\n",
        "model2.add(Bidirectional(LSTM(512, return_sequences=True)))\n",
        "model2.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model2.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model2.add(Bidirectional(LSTM(512, return_sequences=True)))\n",
        "model2.add(TimeDistributed(Dense(num_fr_words, activation='softmax')))\n",
        "\n",
        "# Add early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True)\n",
        "\n",
        "# Print the model summary\n",
        "model2.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "compile and train your new model."
      ],
      "metadata": {
        "id": "EHDvxt9L0C21"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "iK1QvVmaTWI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83f0500c-13dc-4e34-ac56-de165529e8d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "776/776 [==============================] - 71s 71ms/step - loss: 1.3679 - accuracy: 0.6474 - val_loss: 0.7763 - val_accuracy: 0.7653\n",
            "Epoch 2/50\n",
            "776/776 [==============================] - 49s 63ms/step - loss: 0.4889 - accuracy: 0.8488 - val_loss: 0.2685 - val_accuracy: 0.9137\n",
            "Epoch 3/50\n",
            "776/776 [==============================] - 49s 63ms/step - loss: 0.2096 - accuracy: 0.9320 - val_loss: 0.1728 - val_accuracy: 0.9417\n",
            "Epoch 4/50\n",
            "776/776 [==============================] - 49s 63ms/step - loss: 0.1362 - accuracy: 0.9555 - val_loss: 0.1153 - val_accuracy: 0.9611\n",
            "Epoch 5/50\n",
            "776/776 [==============================] - 49s 64ms/step - loss: 0.1060 - accuracy: 0.9653 - val_loss: 0.0970 - val_accuracy: 0.9678\n",
            "Epoch 6/50\n",
            "776/776 [==============================] - 50s 64ms/step - loss: 0.0830 - accuracy: 0.9728 - val_loss: 0.0827 - val_accuracy: 0.9729\n",
            "Epoch 7/50\n",
            "776/776 [==============================] - 50s 64ms/step - loss: 0.0696 - accuracy: 0.9771 - val_loss: 0.0766 - val_accuracy: 0.9759\n",
            "Epoch 8/50\n",
            "776/776 [==============================] - 49s 63ms/step - loss: 0.0623 - accuracy: 0.9794 - val_loss: 0.0746 - val_accuracy: 0.9760\n",
            "Epoch 9/50\n",
            "776/776 [==============================] - 49s 63ms/step - loss: 0.0529 - accuracy: 0.9824 - val_loss: 0.0622 - val_accuracy: 0.9799\n",
            "Epoch 10/50\n",
            "776/776 [==============================] - 49s 63ms/step - loss: 0.0484 - accuracy: 0.9842 - val_loss: 0.0826 - val_accuracy: 0.9733\n",
            "Epoch 11/50\n",
            "776/776 [==============================] - 49s 63ms/step - loss: 0.0417 - accuracy: 0.9862 - val_loss: 0.0625 - val_accuracy: 0.9811\n",
            "Epoch 12/50\n",
            "776/776 [==============================] - 49s 63ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 0.0549 - val_accuracy: 0.9832\n",
            "Epoch 13/50\n",
            "776/776 [==============================] - 49s 64ms/step - loss: 0.0354 - accuracy: 0.9883 - val_loss: 0.0525 - val_accuracy: 0.9838\n",
            "Epoch 14/50\n",
            "776/776 [==============================] - 49s 63ms/step - loss: 0.0300 - accuracy: 0.9901 - val_loss: 0.0635 - val_accuracy: 0.9819\n",
            "Epoch 15/50\n",
            "776/776 [==============================] - 49s 63ms/step - loss: 0.0281 - accuracy: 0.9908 - val_loss: 0.0603 - val_accuracy: 0.9815\n",
            "Epoch 16/50\n",
            "776/776 [==============================] - 49s 64ms/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 0.0543 - val_accuracy: 0.9846\n",
            "Epoch 17/50\n",
            "776/776 [==============================] - 49s 64ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.0652 - val_accuracy: 0.9821\n",
            "Epoch 18/50\n",
            "776/776 [==============================] - 49s 63ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.0489 - val_accuracy: 0.9864\n",
            "Epoch 19/50\n",
            "776/776 [==============================] - 49s 63ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0562 - val_accuracy: 0.9852\n",
            "Epoch 20/50\n",
            "776/776 [==============================] - 49s 63ms/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.0562 - val_accuracy: 0.9854\n",
            "Epoch 21/50\n",
            "776/776 [==============================] - 49s 63ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0601 - val_accuracy: 0.9851\n",
            "Epoch 22/50\n",
            "776/776 [==============================] - 49s 63ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.0679 - val_accuracy: 0.9830\n",
            "Epoch 23/50\n",
            "776/776 [==============================] - 49s 63ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.0523 - val_accuracy: 0.9873\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "# Compile the model\n",
        "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# Train the model\n",
        "history = model2.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=128, callbacks=[early_stop])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a new function that relies on your new model to make predictions."
      ],
      "metadata": {
        "id": "CkpOI2JI0GBx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Gulu8OiXTbae"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "def translate_to_french_1(input_sentence):\n",
        "    # Convert the input sentence to a sequence of integers using the English tokenizer\n",
        "    input_seq = eng_tokenizer.texts_to_sequences([input_sentence])[0]\n",
        "    # Pad the input sequence\n",
        "    input_padded = pad_sequences([input_seq], maxlen=fixed_length, padding='post')\n",
        "    # Use the trained model to generate the output sequence\n",
        "    output_seq = model2.predict(input_padded)[0]\n",
        "    # Convert the output sequence to a sequence of integers\n",
        "    output_seq = np.argmax(output_seq, axis=-1)\n",
        "    # Convert the output sequence to a sentence using the French tokenizer\n",
        "    output_sentence = fr_tokenizer.sequences_to_texts([output_seq])[0]\n",
        "    # Remove the padding token and any other unwanted characters from the output sentence\n",
        "    output_sentence = output_sentence.replace('<pad>', '').replace(' <eos>', '').strip()\n",
        "    return output_sentence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"she is driving the truck\"\n",
        "\n",
        "#Test Your Zaka\n",
        "predicted_french_sentence = translate_to_french_1(input)\n",
        "print(input + ' : \\n' +predicted_french_sentence)  "
      ],
      "metadata": {
        "id": "8CO0pO6-UAeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd01bd01-ef38-4a12-9880-69311a7830a1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "she is driving the truck : \n",
            "elle conduit le camion bleu rouillÃ©\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "def calculate_bleu_score(input_sentence, target_sentence):\n",
        "    # Convert the input sentence to a sequence of integers using the English tokenizer\n",
        "    input_seq = eng_tokenizer.texts_to_sequences([input_sentence])[0]\n",
        "    # Pad the input sequence\n",
        "    input_padded = pad_sequences([input_seq], maxlen=fixed_length, padding='post')\n",
        "    # Use the trained model to generate the output sequence\n",
        "    output_seq = model2.predict(input_padded)[0]\n",
        "    # Convert the output sequence to a sequence of integers\n",
        "    output_seq = np.argmax(output_seq, axis=-1)\n",
        "    # Convert the output sequence to a sentence using the French tokenizer\n",
        "    output_sentence = fr_tokenizer.sequences_to_texts([output_seq])[0]\n",
        "    # Remove the padding token and any other unwanted characters from the output sentence\n",
        "    output_sentence = output_sentence.replace('<pad>', '').replace(' <eos>', '').strip()\n",
        "\n",
        "    # Calculate the BLEU score between the predicted sentence and the target sentence\n",
        "    bleu_score = sentence_bleu([target_sentence.split()], output_sentence.split())\n",
        "    return bleu_score\n",
        "\n",
        "input = \"she is driving the truck\"\n",
        "target_french_sentence = \"elle conduit le camion\"\n",
        "\n",
        "predicted_french_sentence = translate_to_french_1(input)\n",
        "bleu_score = calculate_bleu_score(input, target_french_sentence)\n",
        "\n",
        "print(\"Input sentence: \" + input)\n",
        "print(\"Target French sentence: \" + target_french_sentence)\n",
        "print(\"Predicted French sentence: \" + predicted_french_sentence)\n",
        "print(\"BLEU score: \", bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYJ5r1GyjCf9",
        "outputId": "03660b46-e361-471e-f13f-7f1228f1bb02"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Input sentence: she is driving the truck\n",
            "Target French sentence: elle conduit le camion\n",
            "Predicted French sentence: elle conduit le camion bleu rouillÃ©\n",
            "BLEU score:  0.5081327481546147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is another adjustment in terms of architecture that you might be able to do to improve your model?**"
      ],
      "metadata": {
        "id": "YGeXrjqbZen7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Addition of attention processes might be a potential modification to further enhance the model's performance The model can generate the output sequence while focusing on the portions of the input sequence with the use of attention processes which can improve the quality of the translation."
      ],
      "metadata": {
        "id": "bekjOkjbZlBf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What are some additional ways that we can do to improve the performance of our model?**"
      ],
      "metadata": {
        "id": "pnIN2lD2tn05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "try out different combinations of the hyperparameters learning rate, batch size, and number of epochs.\n",
        "Use pre-trained word embeddings to assist the model better\n",
        "To improve the diversity of the data and avoid overfitting we can use data augmentation techniques such random word deletion, insertion, or replacement in the input phrases."
      ],
      "metadata": {
        "id": "s7_MCCbQt3uq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YFxWzGrkw89I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}