{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Machine Translation Using a Seq2Seq Architecture\n",
        "© 2023, Zaka AI, Inc. All Rights Reserved.\n",
        "\n",
        "---\n",
        "The goal of this colab is to get you more familiar with the Seq2Seq models and their challenges. For this reason, you will be working on machine translation problem where we would have a sentence as input (in english), and the output is gonna be the translated sentence (in french). So just like what happens with Google Translate.\n"
      ],
      "metadata": {
        "id": "xiC75uo6u_Of"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Just to give you a heads up:** We won't be having a model performing like Google translate, but at least we will have an idea about how Google Translate works and the challenges that exist with a translation problem.  "
      ],
      "metadata": {
        "id": "TeK4LPupvg_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "SBTvDTzBv293"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by importing numpy and pandas and then we can add the rest"
      ],
      "metadata": {
        "id": "4_j1ZzS3v6N3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n0IARXAX1e1m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Bidirectional, LSTM, Embedding\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We clone the github repository where our data exists. Here is the github link: https://github.com/zaka-ai/machine_learning_certification/tree/main/Challenge%207 "
      ],
      "metadata": {
        "id": "vAcLqZ7uv-SJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the data"
      ],
      "metadata": {
        "id": "i3hLN42axOjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Your Zaka\n",
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/zaka-ai/machine_learning_certification.git"
      ],
      "metadata": {
        "id": "0-M7cFxTPpqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9199d00a-cb4d-45a3-c3ab-b4077d0293f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'machine_learning_certification'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 43 (delta 10), reused 10 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (43/43), 43.23 MiB | 4.12 MiB/s, done.\n",
            "Updating files: 100% (15/15), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We read the english sentences in a dataframe named \"english\", and the french sentences in a dataframe named \"french\""
      ],
      "metadata": {
        "id": "BaPr0N8cwGAv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kFj8gkP01lGT"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka (English)\n",
        "english = pd.read_csv('machine_learning_certification/Challenge 7/en.csv', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P4A7ZKt32A7s"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka (French)\n",
        "french = pd.read_csv('machine_learning_certification/Challenge 7/fr.csv', header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How many sentences does each of the files contain?**"
      ],
      "metadata": {
        "id": "jr8OO1OhwSp4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XhWJP-b02HKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ad58bc8-ba32-4d8c-8bb2-f892643080c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of English sentences: 137860\n",
            "Number of French sentences: 137860\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "en_sentences = len(english)\n",
        "fr_sentences = len(french)\n",
        "\n",
        "print(\"Number of English sentences:\", en_sentences)\n",
        "print(\"Number of French sentences:\", fr_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us concatenate the 2 dataframes into one dataframe that we call **df** where one column has the english senetnces and the other has the french sentences"
      ],
      "metadata": {
        "id": "ITGJN5tIwkDO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-ZXxahsB2njn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2cb816a7-4cf9-4d79-fcf9-7590fa7709e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   0  \\\n",
              "0  new jersey is sometimes quiet during autumn , ...   \n",
              "1  the united states is usually chilly during jul...   \n",
              "2  california is usually quiet during march , and...   \n",
              "3  the united states is sometimes mild during jun...   \n",
              "4  your least liked fruit is the grape , but my l...   \n",
              "\n",
              "                                                   0  \n",
              "0  new jersey est parfois calme pendant l' automn...  \n",
              "1  les états-unis est généralement froid en juill...  \n",
              "2  california est généralement calme en mars , et...  \n",
              "3  les états-unis est parfois légère en juin , et...  \n",
              "4  votre moins aimé fruit est le raisin , mais mo...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8c9c0b8-7965-47e3-901a-d8216a886c38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new jersey is sometimes quiet during autumn , ...</td>\n",
              "      <td>new jersey est parfois calme pendant l' automn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the united states is usually chilly during jul...</td>\n",
              "      <td>les états-unis est généralement froid en juill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>california is usually quiet during march , and...</td>\n",
              "      <td>california est généralement calme en mars , et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the united states is sometimes mild during jun...</td>\n",
              "      <td>les états-unis est parfois légère en juin , et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>your least liked fruit is the grape , but my l...</td>\n",
              "      <td>votre moins aimé fruit est le raisin , mais mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8c9c0b8-7965-47e3-901a-d8216a886c38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c8c9c0b8-7965-47e3-901a-d8216a886c38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c8c9c0b8-7965-47e3-901a-d8216a886c38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "# Concatenate the English and French dataframes into a single dataframe called \"df\"\n",
        "df = pd.concat([english, french], axis=1)\n",
        "\n",
        "# Display the first few rows of the new dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's name the columns as **English** and **French** so that we access them easier."
      ],
      "metadata": {
        "id": "nAr_caXkwwE7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eOHiQDXx3jFS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9921b796-7d35-4fc7-adb7-d0630ba3d484"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0  new jersey is sometimes quiet during autumn , ...   \n",
              "1  the united states is usually chilly during jul...   \n",
              "2  california is usually quiet during march , and...   \n",
              "3  the united states is sometimes mild during jun...   \n",
              "4  your least liked fruit is the grape , but my l...   \n",
              "\n",
              "                                              French  \n",
              "0  new jersey est parfois calme pendant l' automn...  \n",
              "1  les états-unis est généralement froid en juill...  \n",
              "2  california est généralement calme en mars , et...  \n",
              "3  les états-unis est parfois légère en juin , et...  \n",
              "4  votre moins aimé fruit est le raisin , mais mo...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5045b4c1-34a8-4a16-a773-48fede1bcad0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>French</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new jersey is sometimes quiet during autumn , ...</td>\n",
              "      <td>new jersey est parfois calme pendant l' automn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the united states is usually chilly during jul...</td>\n",
              "      <td>les états-unis est généralement froid en juill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>california is usually quiet during march , and...</td>\n",
              "      <td>california est généralement calme en mars , et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the united states is sometimes mild during jun...</td>\n",
              "      <td>les états-unis est parfois légère en juin , et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>your least liked fruit is the grape , but my l...</td>\n",
              "      <td>votre moins aimé fruit est le raisin , mais mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5045b4c1-34a8-4a16-a773-48fede1bcad0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5045b4c1-34a8-4a16-a773-48fede1bcad0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5045b4c1-34a8-4a16-a773-48fede1bcad0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "df.columns = ['English', 'French']\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pick a sentence and print it in both languages"
      ],
      "metadata": {
        "id": "4xc1TsEHw9yC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QuRVWch23ujo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eceaed70-216c-46ad-ed45-19751268441b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Sentence: she likes pears , grapefruit , and grapes .\n",
            "\n",
            "French Sentence: elle aime les poires , les pamplemousses et les raisins .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "import random\n",
        "\n",
        "# Select a random sentence index\n",
        "idx = random.randint(0, len(df)-1)\n",
        "# Print the corresponding English and French sentences\n",
        "print('English Sentence: {}\\n'.format(df['English'][idx]))\n",
        "print('French Sentence: {}\\n'.format(df['French'][idx]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cleaning Data"
      ],
      "metadata": {
        "id": "FQjXYP1txFCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data that we have is almost clean as we can see, we just need to remove the punctuations inside of it."
      ],
      "metadata": {
        "id": "xgz6jIoVxHUF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6YYOt5QftcFI"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "import string\n",
        "\n",
        "def remove_punctuations(sentence):\n",
        "    # Create a string with all the punctuations to remove\n",
        "    punctuations = string.punctuation\n",
        "    # Create a translation table to remove the punctuations from the sentence\n",
        "    translator = str.maketrans('', '', punctuations)\n",
        "    # Remove the punctuations from the sentence using the translation table\n",
        "    sentence = sentence.translate(translator)\n",
        "    return sentence\n",
        "df['english'] = df['English'].apply(remove_punctuations)\n",
        "df['french'] = df['French'].apply(remove_punctuations)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure that the punctuation is removed by printing the example that you printed earlier."
      ],
      "metadata": {
        "id": "0C1qsC9LxZPb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "T80tiWxe84G7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd6d16f2-e1bc-496a-f7e3-49d14eb2b60d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original English sentence:  she likes pears , grapefruit , and grapes .\n",
            "\n",
            "Cleaned English sentence:  she likes pears  grapefruit  and grapes \n",
            "\n",
            "Original French sentence:  elle aime les poires , les pamplemousses et les raisins .\n",
            "\n",
            "Cleaned French sentence:  elle aime les poires  les pamplemousses et les raisins  \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "print(\"Original English sentence: \", df['English'][idx]+'\\n')\n",
        "print(\"Cleaned English sentence: \", remove_punctuations(df['English'][idx] +'\\n'))\n",
        "\n",
        "print(\"Original French sentence: \", df['French'][idx]+'\\n')\n",
        "print(\"Cleaned French sentence: \", remove_punctuations(df['French'][idx]),'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exploring the Data"
      ],
      "metadata": {
        "id": "ZuFNjoBAx4oN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a column **ENG Length** to the dataset that shows how many words does a sentence contain, and do the same for french in a column called **FR Length**"
      ],
      "metadata": {
        "id": "ATfefzPExi2k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Dakeo81s352S"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "# Add columns for ENG Length and FR Length\n",
        "df['ENG Length'] = df['english'].apply(lambda x: len(x.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "49keasjaPaaK"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "# Add columns for ENG Length and FR Length\n",
        "df['FR Length'] = df['french'].apply(lambda x: len(x.split()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "B3u-1FNdditj",
        "outputId": "6a548566-67a2-4c7a-b96c-07d0d6028ada"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0  new jersey is sometimes quiet during autumn , ...   \n",
              "1  the united states is usually chilly during jul...   \n",
              "2  california is usually quiet during march , and...   \n",
              "3  the united states is sometimes mild during jun...   \n",
              "4  your least liked fruit is the grape , but my l...   \n",
              "\n",
              "                                              French  \\\n",
              "0  new jersey est parfois calme pendant l' automn...   \n",
              "1  les états-unis est généralement froid en juill...   \n",
              "2  california est généralement calme en mars , et...   \n",
              "3  les états-unis est parfois légère en juin , et...   \n",
              "4  votre moins aimé fruit est le raisin , mais mo...   \n",
              "\n",
              "                                             english  \\\n",
              "0  new jersey is sometimes quiet during autumn  a...   \n",
              "1  the united states is usually chilly during jul...   \n",
              "2  california is usually quiet during march  and ...   \n",
              "3  the united states is sometimes mild during jun...   \n",
              "4  your least liked fruit is the grape  but my le...   \n",
              "\n",
              "                                              french  ENG Length  FR Length  \n",
              "0  new jersey est parfois calme pendant l automne...          13         14  \n",
              "1  les étatsunis est généralement froid en juille...          15         13  \n",
              "2  california est généralement calme en mars  et ...          13         13  \n",
              "3  les étatsunis est parfois légère en juin  et i...          14         13  \n",
              "4  votre moins aimé fruit est le raisin  mais mon...          14         14  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0055db9-6cd2-4fc3-9df1-ed63ea126660\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>French</th>\n",
              "      <th>english</th>\n",
              "      <th>french</th>\n",
              "      <th>ENG Length</th>\n",
              "      <th>FR Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new jersey is sometimes quiet during autumn , ...</td>\n",
              "      <td>new jersey est parfois calme pendant l' automn...</td>\n",
              "      <td>new jersey is sometimes quiet during autumn  a...</td>\n",
              "      <td>new jersey est parfois calme pendant l automne...</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the united states is usually chilly during jul...</td>\n",
              "      <td>les états-unis est généralement froid en juill...</td>\n",
              "      <td>the united states is usually chilly during jul...</td>\n",
              "      <td>les étatsunis est généralement froid en juille...</td>\n",
              "      <td>15</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>california is usually quiet during march , and...</td>\n",
              "      <td>california est généralement calme en mars , et...</td>\n",
              "      <td>california is usually quiet during march  and ...</td>\n",
              "      <td>california est généralement calme en mars  et ...</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the united states is sometimes mild during jun...</td>\n",
              "      <td>les états-unis est parfois légère en juin , et...</td>\n",
              "      <td>the united states is sometimes mild during jun...</td>\n",
              "      <td>les étatsunis est parfois légère en juin  et i...</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>your least liked fruit is the grape , but my l...</td>\n",
              "      <td>votre moins aimé fruit est le raisin , mais mo...</td>\n",
              "      <td>your least liked fruit is the grape  but my le...</td>\n",
              "      <td>votre moins aimé fruit est le raisin  mais mon...</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0055db9-6cd2-4fc3-9df1-ed63ea126660')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0055db9-6cd2-4fc3-9df1-ed63ea126660 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0055db9-6cd2-4fc3-9df1-ed63ea126660');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the distribution of the lengths of english sentences and french sentences."
      ],
      "metadata": {
        "id": "AjQLW0K5xwx1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_q_UIMJ09L24"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TSn4L7kW9R7g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "f28e30ce-65fd-42d0-bb00-a4b277c5af2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "# Create a figure with two subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Plot the distribution of English sentence lengths\n",
        "axs[0].hist(df['ENG Length'], bins=50, color='blue')\n",
        "axs[0].set_xlabel('Length of English sentences')\n",
        "axs[0].set_ylabel('Frequency')\n",
        "\n",
        "# Plot the distribution of French sentence lengths\n",
        "axs[1].hist(df['FR Length'], bins=50, color='red')\n",
        "axs[1].set_xlabel('Length of French sentences')\n",
        "axs[1].set_ylabel('Frequency')\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the maximum length of an english sentence and the maximum length of a french sentence. "
      ],
      "metadata": {
        "id": "BDXb2d9ix9DV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BpnBB04U_lHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca366938-47d1-4447-a99e-2e6c0b25e7a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum length of an English sentence: 15\n",
            "Maximum length of an french sentence: 21\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "max_eng_length = df['ENG Length'].max()\n",
        "max_fr_length = df['FR Length'].max()\n",
        "print(\"Maximum length of an English sentence:\", max_eng_length)\n",
        "print(\"Maximum length of an french sentence:\", max_fr_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing the Data"
      ],
      "metadata": {
        "id": "s4s-spsRyGJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order for the data to be fed to the model, it has to be tokenized and padded. "
      ],
      "metadata": {
        "id": "N0ZmIT2GyJMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Tokenization"
      ],
      "metadata": {
        "id": "R0r9z-eErm9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To tokenize english and french sentences, we can use only one tokenizer. True or False?**"
      ],
      "metadata": {
        "id": "X5L_zkhfyQuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Share Your Zaka]"
      ],
      "metadata": {
        "id": "1Z0ZcNOeyauD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the sentences that we have."
      ],
      "metadata": {
        "id": "814mKDFiymcY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "aiXlciqFuQzW"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Tokenize the English sentences\n",
        "eng_tokenizer = Tokenizer()\n",
        "eng_tokenizer.fit_on_texts(df['english'])\n",
        "eng_sequences = eng_tokenizer.texts_to_sequences(df['english'])\n",
        "\n",
        "# Tokenize the French sentences\n",
        "fr_tokenizer = Tokenizer()\n",
        "fr_tokenizer.fit_on_texts(df['french'])\n",
        "fr_sequences = fr_tokenizer.texts_to_sequences(df['french'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How many unique words do we have in english and in french?**"
      ],
      "metadata": {
        "id": "aUN01jDXys9B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1WahkdzKvIlO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab294df-9160-4ec5-d11e-774c366207ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words in English sentences: 200\n",
            "Number of unique words in French sentences: 345\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "# Find the number of unique words in the English sentences\n",
        "num_eng_words = len(eng_tokenizer.word_index)+1\n",
        "print(\"Number of unique words in English sentences:\", num_eng_words)\n",
        "\n",
        "# Find the number of unique words in the French sentences\n",
        "num_fr_words = len(fr_tokenizer.word_index)+1\n",
        "print(\"Number of unique words in French sentences:\", num_fr_words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Padding"
      ],
      "metadata": {
        "id": "g0C2RJjArtJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What should be the length of the sequences that we have after padding?**"
      ],
      "metadata": {
        "id": "vXdTXMo5y8oB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Share your Zaka]"
      ],
      "metadata": {
        "id": "9wtHQsgXzImq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform padding on the sequences that we have."
      ],
      "metadata": {
        "id": "hRXayRzVzQD4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oNdO9EZrxvmN"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "# Pad the English sequences\n",
        "padded_eng_sequences = pad_sequences(eng_sequences, maxlen=max_eng_length, padding='post')\n",
        "# Pad the French sequences\n",
        "padded_fr_sequences = pad_sequences(fr_sequences, maxlen=None, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the padded sequences\n",
        "print(\"Padded English sequence:\\n\", padded_eng_sequences[0])\n",
        "print(\"Padded French sequence:\\n\", padded_fr_sequences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L9tT8D209Re",
        "outputId": "6e1d4411-9d23-4c0a-88b2-9cf98e2e8ee9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded English sequence:\n",
            " [17 23  1  8 67  4 39  7  3  1 55  2 44  0  0]\n",
            "Padded French sequence:\n",
            " [ 34  33   1   8  66  36  11  24   6   3   1 111   2  49   0   0   0   0\n",
            "   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modeling"
      ],
      "metadata": {
        "id": "JxvvVU3ezUHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After preprrocessing the data, we can build our model. Start by building a baseline architecture relying on one directional RNNs, LSTMs, or GRUs. It will be good to lookup how to build Seq2Seq models, there are some new layers that will help you like RepeatVector and TimeDistributed."
      ],
      "metadata": {
        "id": "FEKujJUEzVux"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9oydzHkr3zDC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ceea62-1f4b-40d4-c5e6-d1fdc88c8663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 15, 128)           25728     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 15, 256)           394240    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 15, 128)           197120    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 15, 345)           44505     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 661,593\n",
            "Trainable params: 661,593\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Embedding, TimeDistributed\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add an embedding layer to convert the input sequences into dense vectors of fixed size\n",
        "model.add(Embedding(num_eng_words + 1, 128, input_length=max_eng_length))\n",
        "\n",
        "# Add a one-directional LSTM layer with 256 units\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "\n",
        "# Add another one-directional LSTM layer with 128 units\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "\n",
        "# Add a dense output layer with softmax activation to output the predicted probabilities for each class\n",
        "model.add(Dense(units=num_fr_words, activation='softmax'))\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile and train the model. \n",
        "**FYI:** While specifying the architecture of your model and the number of epochs for training, keeep in your mind that your model might take A LOT of time to train."
      ],
      "metadata": {
        "id": "aP10HtNBzpT0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "lWw4nBNIFp9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a04fe6-b276-48d6-95c9-881db0f63ba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "431/431 [==============================] - 24s 34ms/step - loss: 2.8915 - accuracy: 0.3636 - val_loss: 1.9478 - val_accuracy: 0.4982\n",
            "Epoch 2/50\n",
            "431/431 [==============================] - 7s 16ms/step - loss: 1.6122 - accuracy: 0.5638 - val_loss: 1.3750 - val_accuracy: 0.6205\n",
            "Epoch 3/50\n",
            "431/431 [==============================] - 6s 15ms/step - loss: 1.2099 - accuracy: 0.6650 - val_loss: 1.0553 - val_accuracy: 0.7091\n",
            "Epoch 4/50\n",
            "431/431 [==============================] - 6s 15ms/step - loss: 0.9449 - accuracy: 0.7421 - val_loss: 0.8433 - val_accuracy: 0.7669\n",
            "Epoch 5/50\n",
            "431/431 [==============================] - 6s 15ms/step - loss: 0.7656 - accuracy: 0.7874 - val_loss: 0.7008 - val_accuracy: 0.8015\n",
            "Epoch 6/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.6648 - accuracy: 0.8087 - val_loss: 0.6234 - val_accuracy: 0.8172\n",
            "Epoch 7/50\n",
            "431/431 [==============================] - 6s 15ms/step - loss: 0.6093 - accuracy: 0.8194 - val_loss: 0.6088 - val_accuracy: 0.8170\n",
            "Epoch 8/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.5729 - accuracy: 0.8274 - val_loss: 0.5479 - val_accuracy: 0.8347\n",
            "Epoch 9/50\n",
            "431/431 [==============================] - 6s 15ms/step - loss: 0.5438 - accuracy: 0.8346 - val_loss: 0.5346 - val_accuracy: 0.8361\n",
            "Epoch 10/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.5218 - accuracy: 0.8402 - val_loss: 0.5094 - val_accuracy: 0.8440\n",
            "Epoch 11/50\n",
            "431/431 [==============================] - 7s 15ms/step - loss: 0.5035 - accuracy: 0.8448 - val_loss: 0.5048 - val_accuracy: 0.8441\n",
            "Epoch 12/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.4894 - accuracy: 0.8485 - val_loss: 0.4838 - val_accuracy: 0.8509\n",
            "Epoch 13/50\n",
            "431/431 [==============================] - 6s 15ms/step - loss: 0.4775 - accuracy: 0.8516 - val_loss: 0.4759 - val_accuracy: 0.8528\n",
            "Epoch 14/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.4666 - accuracy: 0.8545 - val_loss: 0.4711 - val_accuracy: 0.8538\n",
            "Epoch 15/50\n",
            "431/431 [==============================] - 7s 15ms/step - loss: 0.4575 - accuracy: 0.8568 - val_loss: 0.4629 - val_accuracy: 0.8556\n",
            "Epoch 16/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.4509 - accuracy: 0.8583 - val_loss: 0.4581 - val_accuracy: 0.8569\n",
            "Epoch 17/50\n",
            "431/431 [==============================] - 6s 15ms/step - loss: 0.4432 - accuracy: 0.8605 - val_loss: 0.4560 - val_accuracy: 0.8570\n",
            "Epoch 18/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.4376 - accuracy: 0.8617 - val_loss: 0.4457 - val_accuracy: 0.8601\n",
            "Epoch 19/50\n",
            "431/431 [==============================] - 6s 15ms/step - loss: 0.4325 - accuracy: 0.8630 - val_loss: 0.4466 - val_accuracy: 0.8599\n",
            "Epoch 20/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.4294 - accuracy: 0.8635 - val_loss: 0.4433 - val_accuracy: 0.8612\n",
            "Epoch 21/50\n",
            "431/431 [==============================] - 7s 15ms/step - loss: 0.4245 - accuracy: 0.8647 - val_loss: 0.4416 - val_accuracy: 0.8616\n",
            "Epoch 22/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.4202 - accuracy: 0.8659 - val_loss: 0.4385 - val_accuracy: 0.8621\n",
            "Epoch 23/50\n",
            "431/431 [==============================] - 7s 15ms/step - loss: 0.4171 - accuracy: 0.8667 - val_loss: 0.4369 - val_accuracy: 0.8626\n",
            "Epoch 24/50\n",
            "431/431 [==============================] - 7s 15ms/step - loss: 0.4158 - accuracy: 0.8668 - val_loss: 0.4325 - val_accuracy: 0.8640\n",
            "Epoch 25/50\n",
            "431/431 [==============================] - 7s 15ms/step - loss: 0.4110 - accuracy: 0.8680 - val_loss: 0.4333 - val_accuracy: 0.8638\n",
            "Epoch 26/50\n",
            "431/431 [==============================] - 7s 15ms/step - loss: 0.4093 - accuracy: 0.8683 - val_loss: 0.4299 - val_accuracy: 0.8653\n",
            "Epoch 27/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.4063 - accuracy: 0.8690 - val_loss: 0.4316 - val_accuracy: 0.8633\n",
            "Epoch 28/50\n",
            "431/431 [==============================] - 6s 15ms/step - loss: 0.4042 - accuracy: 0.8695 - val_loss: 0.4281 - val_accuracy: 0.8650\n",
            "Epoch 29/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.4025 - accuracy: 0.8697 - val_loss: 0.4276 - val_accuracy: 0.8652\n",
            "Epoch 30/50\n",
            "431/431 [==============================] - 7s 15ms/step - loss: 0.4003 - accuracy: 0.8706 - val_loss: 0.4285 - val_accuracy: 0.8649\n",
            "Epoch 31/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.3990 - accuracy: 0.8706 - val_loss: 0.4279 - val_accuracy: 0.8651\n",
            "Epoch 32/50\n",
            "431/431 [==============================] - 7s 16ms/step - loss: 0.3965 - accuracy: 0.8711 - val_loss: 0.4303 - val_accuracy: 0.8641\n",
            "Epoch 33/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.3965 - accuracy: 0.8711 - val_loss: 0.4278 - val_accuracy: 0.8644\n",
            "Epoch 34/50\n",
            "431/431 [==============================] - 7s 15ms/step - loss: 0.3931 - accuracy: 0.8720 - val_loss: 0.4262 - val_accuracy: 0.8650\n",
            "Epoch 35/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.3913 - accuracy: 0.8723 - val_loss: 0.4282 - val_accuracy: 0.8650\n",
            "Epoch 36/50\n",
            "431/431 [==============================] - 7s 16ms/step - loss: 0.3903 - accuracy: 0.8725 - val_loss: 0.4255 - val_accuracy: 0.8653\n",
            "Epoch 37/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.3893 - accuracy: 0.8728 - val_loss: 0.4264 - val_accuracy: 0.8646\n",
            "Epoch 38/50\n",
            "431/431 [==============================] - 7s 16ms/step - loss: 0.3869 - accuracy: 0.8732 - val_loss: 0.4246 - val_accuracy: 0.8661\n",
            "Epoch 39/50\n",
            "431/431 [==============================] - 6s 15ms/step - loss: 0.3863 - accuracy: 0.8735 - val_loss: 0.4263 - val_accuracy: 0.8654\n",
            "Epoch 40/50\n",
            "431/431 [==============================] - 6s 15ms/step - loss: 0.3853 - accuracy: 0.8735 - val_loss: 0.4259 - val_accuracy: 0.8658\n",
            "Epoch 41/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.3879 - accuracy: 0.8728 - val_loss: 0.4253 - val_accuracy: 0.8652\n",
            "Epoch 42/50\n",
            "431/431 [==============================] - 7s 15ms/step - loss: 0.3824 - accuracy: 0.8741 - val_loss: 0.4256 - val_accuracy: 0.8664\n",
            "Epoch 43/50\n",
            "431/431 [==============================] - 7s 15ms/step - loss: 0.3809 - accuracy: 0.8746 - val_loss: 0.4264 - val_accuracy: 0.8650\n",
            "Epoch 44/50\n",
            "431/431 [==============================] - 6s 15ms/step - loss: 0.3812 - accuracy: 0.8742 - val_loss: 0.4286 - val_accuracy: 0.8646\n",
            "Epoch 45/50\n",
            "431/431 [==============================] - 7s 15ms/step - loss: 0.3799 - accuracy: 0.8746 - val_loss: 0.4278 - val_accuracy: 0.8641\n",
            "Epoch 46/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.3783 - accuracy: 0.8749 - val_loss: 0.4294 - val_accuracy: 0.8654\n",
            "Epoch 47/50\n",
            "431/431 [==============================] - 7s 15ms/step - loss: 0.3776 - accuracy: 0.8752 - val_loss: 0.4305 - val_accuracy: 0.8655\n",
            "Epoch 48/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.3780 - accuracy: 0.8749 - val_loss: 0.4329 - val_accuracy: 0.8647\n",
            "Epoch 49/50\n",
            "431/431 [==============================] - 7s 15ms/step - loss: 0.3763 - accuracy: 0.8754 - val_loss: 0.4306 - val_accuracy: 0.8644\n",
            "Epoch 50/50\n",
            "431/431 [==============================] - 6s 14ms/step - loss: 0.3751 - accuracy: 0.8758 - val_loss: 0.4296 - val_accuracy: 0.8652\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd401b7e190>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Pad the French sequences to match the length of the English sequences\n",
        "padded_fr_sequences = pad_sequences(fr_sequences, maxlen=max_eng_length, padding='post')\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_eng, val_eng, train_fr, val_fr = train_test_split(padded_eng_sequences, padded_fr_sequences, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model using the training data and validate using the validation data\n",
        "model.fit(train_eng, to_categorical(train_fr, num_fr_words), batch_size=256, epochs=50, validation_data=(val_eng, to_categorical(val_fr, num_fr_words)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function that gets an input sentence in english and gives the output sentence in the french language."
      ],
      "metadata": {
        "id": "9UoEcxyJztiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Your Zaka\n",
        "def translate_to_french(input_sentence):\n",
        "    # Convert the input sentence to a sequence of integers using the English tokenizer\n",
        "    input_seq = eng_tokenizer.texts_to_sequences([input_sentence])[0]\n",
        "    # Pad the input sequence\n",
        "    input_padded = pad_sequences([input_seq], maxlen=max_eng_length, padding='post')\n",
        "    # Use the trained model to generate the output sequence\n",
        "    output_seq = model.predict(input_padded)[0]\n",
        "    # Convert the output sequence to a sequence of integers\n",
        "    output_seq = np.argmax(output_seq, axis=-1)\n",
        "    # Convert the output sequence to a sentence using the French tokenizer\n",
        "    output_sentence = fr_tokenizer.sequences_to_texts([output_seq])[0]\n",
        "    # Remove the padding token from the output sentence\n",
        "    output_sentence = output_sentence.replace('<pad>', '').strip()\n",
        "    return output_sentence"
      ],
      "metadata": {
        "id": "fUU_RdCxYpM6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the following sentence"
      ],
      "metadata": {
        "id": "XUQIcAjWz3bt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "fDmNqnZIQMko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d05798f-e537-4f29-cd30-cfed792f4c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "she is driving the truck : \n",
            "elle conduit cette voiture jaune\n"
          ]
        }
      ],
      "source": [
        "input = \"she is driving the truck\"\n",
        "\n",
        "#Test Your Zaka\n",
        "predicted_french_sentence = translate_to_french(input)\n",
        "print(input + ' : \\n' +predicted_french_sentence)  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU \n",
        "from keras.layers import GRU\n",
        "# Define the model\n",
        "model_1 = Sequential()\n",
        "\n",
        "# Add an embedding layer to convert the input sequences into dense vectors of fixed size\n",
        "model_1.add(Embedding(num_eng_words + 1, 512, input_length=max_eng_length))\n",
        "\n",
        "# Add a one-directional GRU layer with 128 units\n",
        "model_1.add(GRU(256, return_sequences=True))\n",
        "\n",
        "# Add a dense output layer with softmax activation to output the predicted probabilities for each class\n",
        "model_1.add(Dense(num_fr_words, activation='softmax'))\n",
        "# Compile the model with categorical cross-entropy loss and Adam optimizer\n",
        "model_1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model_1.summary()\n",
        "# Pad the French sequences to match the length of the English sequences\n",
        "padded_fr_sequences = pad_sequences(fr_sequences, maxlen=max_eng_length, padding='post')\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_eng, val_eng, train_fr, val_fr = train_test_split(padded_eng_sequences, padded_fr_sequences, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model using the training data and validate using the validation data\n",
        "model_1.fit(train_eng, to_categorical(train_fr, num_fr_words), batch_size=128, epochs=50, validation_data=(val_eng, to_categorical(val_fr, num_fr_words)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBI4Riz8sWDD",
        "outputId": "f5a38380-94b0-4f6f-c491-cac62e03e385"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 15, 512)           102912    \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 15, 256)           591360    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 15, 345)           88665     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 782,937\n",
            "Trainable params: 782,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "862/862 [==============================] - 35s 37ms/step - loss: 1.2225 - accuracy: 0.6889 - val_loss: 0.6396 - val_accuracy: 0.8047\n",
            "Epoch 2/50\n",
            "862/862 [==============================] - 10s 11ms/step - loss: 0.5797 - accuracy: 0.8196 - val_loss: 0.5300 - val_accuracy: 0.8344\n",
            "Epoch 3/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.5109 - accuracy: 0.8396 - val_loss: 0.4891 - val_accuracy: 0.8461\n",
            "Epoch 4/50\n",
            "862/862 [==============================] - 10s 11ms/step - loss: 0.4781 - accuracy: 0.8487 - val_loss: 0.4690 - val_accuracy: 0.8523\n",
            "Epoch 5/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.4589 - accuracy: 0.8541 - val_loss: 0.4589 - val_accuracy: 0.8555\n",
            "Epoch 6/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.4441 - accuracy: 0.8585 - val_loss: 0.4485 - val_accuracy: 0.8575\n",
            "Epoch 7/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.4359 - accuracy: 0.8607 - val_loss: 0.4405 - val_accuracy: 0.8601\n",
            "Epoch 8/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.4284 - accuracy: 0.8625 - val_loss: 0.4414 - val_accuracy: 0.8597\n",
            "Epoch 9/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.4238 - accuracy: 0.8636 - val_loss: 0.4330 - val_accuracy: 0.8627\n",
            "Epoch 10/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.4175 - accuracy: 0.8653 - val_loss: 0.4319 - val_accuracy: 0.8630\n",
            "Epoch 11/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.4144 - accuracy: 0.8660 - val_loss: 0.4314 - val_accuracy: 0.8627\n",
            "Epoch 12/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.4120 - accuracy: 0.8666 - val_loss: 0.4315 - val_accuracy: 0.8633\n",
            "Epoch 13/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.4093 - accuracy: 0.8672 - val_loss: 0.4311 - val_accuracy: 0.8633\n",
            "Epoch 14/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.4058 - accuracy: 0.8682 - val_loss: 0.4311 - val_accuracy: 0.8627\n",
            "Epoch 15/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.4036 - accuracy: 0.8687 - val_loss: 0.4314 - val_accuracy: 0.8626\n",
            "Epoch 16/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.4012 - accuracy: 0.8691 - val_loss: 0.4323 - val_accuracy: 0.8626\n",
            "Epoch 17/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.3995 - accuracy: 0.8694 - val_loss: 0.4284 - val_accuracy: 0.8642\n",
            "Epoch 18/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3970 - accuracy: 0.8702 - val_loss: 0.4284 - val_accuracy: 0.8645\n",
            "Epoch 19/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.3976 - accuracy: 0.8700 - val_loss: 0.4275 - val_accuracy: 0.8643\n",
            "Epoch 20/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3948 - accuracy: 0.8705 - val_loss: 0.4290 - val_accuracy: 0.8633\n",
            "Epoch 21/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3947 - accuracy: 0.8704 - val_loss: 0.4274 - val_accuracy: 0.8655\n",
            "Epoch 22/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3920 - accuracy: 0.8709 - val_loss: 0.4278 - val_accuracy: 0.8650\n",
            "Epoch 23/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3920 - accuracy: 0.8713 - val_loss: 0.4300 - val_accuracy: 0.8643\n",
            "Epoch 24/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3902 - accuracy: 0.8714 - val_loss: 0.4307 - val_accuracy: 0.8641\n",
            "Epoch 25/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3894 - accuracy: 0.8717 - val_loss: 0.4306 - val_accuracy: 0.8643\n",
            "Epoch 26/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.3873 - accuracy: 0.8722 - val_loss: 0.4300 - val_accuracy: 0.8644\n",
            "Epoch 27/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3854 - accuracy: 0.8725 - val_loss: 0.4324 - val_accuracy: 0.8641\n",
            "Epoch 28/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.3885 - accuracy: 0.8716 - val_loss: 0.4352 - val_accuracy: 0.8639\n",
            "Epoch 29/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3847 - accuracy: 0.8725 - val_loss: 0.4313 - val_accuracy: 0.8657\n",
            "Epoch 30/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.3841 - accuracy: 0.8730 - val_loss: 0.4318 - val_accuracy: 0.8645\n",
            "Epoch 31/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3850 - accuracy: 0.8724 - val_loss: 0.4325 - val_accuracy: 0.8637\n",
            "Epoch 32/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3817 - accuracy: 0.8734 - val_loss: 0.4318 - val_accuracy: 0.8635\n",
            "Epoch 33/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.3831 - accuracy: 0.8728 - val_loss: 0.4353 - val_accuracy: 0.8631\n",
            "Epoch 34/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.3814 - accuracy: 0.8731 - val_loss: 0.4348 - val_accuracy: 0.8646\n",
            "Epoch 35/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3806 - accuracy: 0.8736 - val_loss: 0.4370 - val_accuracy: 0.8635\n",
            "Epoch 36/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.3805 - accuracy: 0.8735 - val_loss: 0.4330 - val_accuracy: 0.8641\n",
            "Epoch 37/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3791 - accuracy: 0.8738 - val_loss: 0.4339 - val_accuracy: 0.8643\n",
            "Epoch 38/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3791 - accuracy: 0.8739 - val_loss: 0.4386 - val_accuracy: 0.8635\n",
            "Epoch 39/50\n",
            "862/862 [==============================] - 9s 11ms/step - loss: 0.3782 - accuracy: 0.8737 - val_loss: 0.4341 - val_accuracy: 0.8650\n",
            "Epoch 40/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.3771 - accuracy: 0.8742 - val_loss: 0.4368 - val_accuracy: 0.8638\n",
            "Epoch 41/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3797 - accuracy: 0.8734 - val_loss: 0.4352 - val_accuracy: 0.8639\n",
            "Epoch 42/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3768 - accuracy: 0.8743 - val_loss: 0.4368 - val_accuracy: 0.8635\n",
            "Epoch 43/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3742 - accuracy: 0.8749 - val_loss: 0.4378 - val_accuracy: 0.8645\n",
            "Epoch 44/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.3746 - accuracy: 0.8745 - val_loss: 0.4385 - val_accuracy: 0.8640\n",
            "Epoch 45/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3805 - accuracy: 0.8731 - val_loss: 0.4406 - val_accuracy: 0.8628\n",
            "Epoch 46/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3741 - accuracy: 0.8748 - val_loss: 0.4384 - val_accuracy: 0.8647\n",
            "Epoch 47/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.3737 - accuracy: 0.8749 - val_loss: 0.4403 - val_accuracy: 0.8632\n",
            "Epoch 48/50\n",
            "862/862 [==============================] - 8s 10ms/step - loss: 0.3728 - accuracy: 0.8750 - val_loss: 0.4414 - val_accuracy: 0.8640\n",
            "Epoch 49/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.3746 - accuracy: 0.8744 - val_loss: 0.4410 - val_accuracy: 0.8636\n",
            "Epoch 50/50\n",
            "862/862 [==============================] - 8s 9ms/step - loss: 0.3731 - accuracy: 0.8748 - val_loss: 0.4422 - val_accuracy: 0.8631\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6e174aa9a0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_to_french_1(input_sentence):\n",
        "    # Convert the input sentence to a sequence of integers using the English tokenizer\n",
        "    input_seq = eng_tokenizer.texts_to_sequences([input_sentence])[0]\n",
        "    # Pad the input sequence\n",
        "    input_padded = pad_sequences([input_seq], maxlen=max_eng_length, padding='post')\n",
        "    # Use the trained model to generate the output sequence\n",
        "    output_seq = model_1.predict(input_padded)[0]\n",
        "    # Convert the output sequence to a sequence of integers\n",
        "    output_seq = np.argmax(output_seq, axis=-1)\n",
        "    # Convert the output sequence to a sentence using the French tokenizer\n",
        "    output_sentence = fr_tokenizer.sequences_to_texts([output_seq])[0]\n",
        "    # Remove the padding token from the output sentence\n",
        "    output_sentence = output_sentence.replace('<pad>', '').strip()\n",
        "    return output_sentence"
      ],
      "metadata": {
        "id": "I68YkIMUynpx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"she is driving the truck\"\n",
        "\n",
        "#Test Your Zaka\n",
        "predicted_french_sentence = translate_to_french_1(input)\n",
        "print(input + ' : \\n' +predicted_french_sentence)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-bTBV1dyssk",
        "outputId": "e2bd6652-7477-4e4e-dd5a-0cf358721b16"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 399ms/step\n",
            "she is driving the truck : \n",
            "elle conduit la nouveau\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to improve your model by modifying the architecture to take into account bidirectionality which is very useful in Machine Translation. Create a new model called model2"
      ],
      "metadata": {
        "id": "wdI2XhaBz6CN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Ch28BLsbGnCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b2edb09-1379-451c-a64d-cfa7112dcdf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 15, 128)           25728     \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 15, 512)          788480    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 15, 256)          656384    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 15, 345)           88665     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,559,257\n",
            "Trainable params: 1,559,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "from keras.layers import Bidirectional\n",
        "\n",
        "# Define the model\n",
        "model_2 = Sequential()\n",
        "\n",
        "# Add an embedding layer to convert the input sequences into dense vectors of fixed size\n",
        "model_2.add(Embedding(num_eng_words + 1, 128, input_length=max_eng_length))\n",
        "\n",
        "# Add a bidirectional LSTM layer with 256 units\n",
        "model_2.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "\n",
        "# Add another bidirectional LSTM layer with 128 units\n",
        "model_2.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "\n",
        "# Add a dense output layer with softmax activation to output the predicted probabilities for each class\n",
        "model_2.add(Dense(units=num_fr_words, activation='softmax'))\n",
        "\n",
        "# Print the model summary\n",
        "model_2.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "compile and train your new model."
      ],
      "metadata": {
        "id": "EHDvxt9L0C21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "jX0VA-3KGuqW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "iK1QvVmaTWI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a92a10-d734-470d-8f01-3a6d805aeda1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "862/862 [==============================] - 40s 29ms/step - loss: 1.8772 - accuracy: 0.5237 - val_loss: 1.1650 - val_accuracy: 0.6667\n",
            "Epoch 2/50\n",
            "862/862 [==============================] - 15s 18ms/step - loss: 0.8331 - accuracy: 0.7613 - val_loss: 0.5473 - val_accuracy: 0.8453\n",
            "Epoch 3/50\n",
            "862/862 [==============================] - 16s 18ms/step - loss: 0.4304 - accuracy: 0.8736 - val_loss: 0.3309 - val_accuracy: 0.8992\n",
            "Epoch 4/50\n",
            "862/862 [==============================] - 15s 18ms/step - loss: 0.2942 - accuracy: 0.9093 - val_loss: 0.2533 - val_accuracy: 0.9210\n",
            "Epoch 5/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.2224 - accuracy: 0.9310 - val_loss: 0.1985 - val_accuracy: 0.9388\n",
            "Epoch 6/50\n",
            "862/862 [==============================] - 15s 18ms/step - loss: 0.1767 - accuracy: 0.9451 - val_loss: 0.1762 - val_accuracy: 0.9453\n",
            "Epoch 7/50\n",
            "862/862 [==============================] - 15s 18ms/step - loss: 0.1441 - accuracy: 0.9554 - val_loss: 0.1493 - val_accuracy: 0.9536\n",
            "Epoch 8/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.1193 - accuracy: 0.9628 - val_loss: 0.1287 - val_accuracy: 0.9599\n",
            "Epoch 9/50\n",
            "862/862 [==============================] - 15s 18ms/step - loss: 0.1037 - accuracy: 0.9675 - val_loss: 0.1108 - val_accuracy: 0.9658\n",
            "Epoch 10/50\n",
            "862/862 [==============================] - 15s 17ms/step - loss: 0.0885 - accuracy: 0.9721 - val_loss: 0.1044 - val_accuracy: 0.9677\n",
            "Epoch 11/50\n",
            "862/862 [==============================] - 15s 17ms/step - loss: 0.0762 - accuracy: 0.9759 - val_loss: 0.1021 - val_accuracy: 0.9690\n",
            "Epoch 12/50\n",
            "862/862 [==============================] - 15s 18ms/step - loss: 0.0675 - accuracy: 0.9787 - val_loss: 0.0972 - val_accuracy: 0.9706\n",
            "Epoch 13/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.0624 - accuracy: 0.9801 - val_loss: 0.0878 - val_accuracy: 0.9734\n",
            "Epoch 14/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.0535 - accuracy: 0.9829 - val_loss: 0.0851 - val_accuracy: 0.9742\n",
            "Epoch 15/50\n",
            "862/862 [==============================] - 16s 18ms/step - loss: 0.0477 - accuracy: 0.9848 - val_loss: 0.0827 - val_accuracy: 0.9756\n",
            "Epoch 16/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.0427 - accuracy: 0.9863 - val_loss: 0.0837 - val_accuracy: 0.9760\n",
            "Epoch 17/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.0810 - val_accuracy: 0.9771\n",
            "Epoch 18/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.0350 - accuracy: 0.9891 - val_loss: 0.0977 - val_accuracy: 0.9735\n",
            "Epoch 19/50\n",
            "862/862 [==============================] - 15s 18ms/step - loss: 0.0348 - accuracy: 0.9889 - val_loss: 0.0835 - val_accuracy: 0.9772\n",
            "Epoch 20/50\n",
            "862/862 [==============================] - 15s 18ms/step - loss: 0.0293 - accuracy: 0.9907 - val_loss: 0.0897 - val_accuracy: 0.9763\n",
            "Epoch 21/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.0290 - accuracy: 0.9910 - val_loss: 0.0817 - val_accuracy: 0.9782\n",
            "Epoch 22/50\n",
            "862/862 [==============================] - 15s 18ms/step - loss: 0.0261 - accuracy: 0.9919 - val_loss: 0.0794 - val_accuracy: 0.9797\n",
            "Epoch 23/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0789 - val_accuracy: 0.9796\n",
            "Epoch 24/50\n",
            "862/862 [==============================] - 15s 17ms/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 0.0917 - val_accuracy: 0.9763\n",
            "Epoch 25/50\n",
            "862/862 [==============================] - 16s 18ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.0888 - val_accuracy: 0.9777\n",
            "Epoch 26/50\n",
            "862/862 [==============================] - 15s 18ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.0829 - val_accuracy: 0.9792\n",
            "Epoch 27/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.0795 - val_accuracy: 0.9809\n",
            "Epoch 28/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.0926 - val_accuracy: 0.9776\n",
            "Epoch 29/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0896 - val_accuracy: 0.9793\n",
            "Epoch 30/50\n",
            "862/862 [==============================] - 15s 18ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.0885 - val_accuracy: 0.9793\n",
            "Epoch 31/50\n",
            "862/862 [==============================] - 15s 17ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0845 - val_accuracy: 0.9810\n",
            "Epoch 32/50\n",
            "862/862 [==============================] - 15s 18ms/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.0828 - val_accuracy: 0.9820\n",
            "Epoch 33/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0932 - val_accuracy: 0.9791\n",
            "Epoch 34/50\n",
            "862/862 [==============================] - 15s 18ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0936 - val_accuracy: 0.9778\n",
            "Epoch 35/50\n",
            "862/862 [==============================] - 15s 17ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.0895 - val_accuracy: 0.9800\n",
            "Epoch 36/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.0878 - val_accuracy: 0.9794\n",
            "Epoch 37/50\n",
            "862/862 [==============================] - 15s 17ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.0879 - val_accuracy: 0.9809\n",
            "Epoch 38/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0877 - val_accuracy: 0.9816\n",
            "Epoch 39/50\n",
            "862/862 [==============================] - 15s 18ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0868 - val_accuracy: 0.9812\n",
            "Epoch 40/50\n",
            "862/862 [==============================] - 15s 17ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.0905 - val_accuracy: 0.9808\n",
            "Epoch 41/50\n",
            "862/862 [==============================] - 15s 17ms/step - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.0919 - val_accuracy: 0.9803\n",
            "Epoch 42/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.0919 - val_accuracy: 0.9814\n",
            "Epoch 43/50\n",
            "862/862 [==============================] - 14s 16ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.0936 - val_accuracy: 0.9809\n",
            "Epoch 44/50\n",
            "862/862 [==============================] - 14s 16ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.0957 - val_accuracy: 0.9807\n",
            "Epoch 45/50\n",
            "862/862 [==============================] - 14s 17ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.0969 - val_accuracy: 0.9809\n",
            "Epoch 46/50\n",
            "862/862 [==============================] - 14s 16ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.0982 - val_accuracy: 0.9809\n",
            "Epoch 47/50\n",
            "862/862 [==============================] - 14s 16ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0975 - val_accuracy: 0.9808\n",
            "Epoch 48/50\n",
            "862/862 [==============================] - 14s 16ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.0977 - val_accuracy: 0.9806\n",
            "Epoch 49/50\n",
            "862/862 [==============================] - 14s 16ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.0944 - val_accuracy: 0.9822\n",
            "Epoch 50/50\n",
            "862/862 [==============================] - 15s 17ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.1027 - val_accuracy: 0.9801\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6eae815b50>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "#Test Your Zaka\n",
        "# Compile the model with categorical cross-entropy loss and Adam optimizer\n",
        "model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Pad the French sequences to match the length of the English sequences\n",
        "padded_fr_sequences = pad_sequences(fr_sequences, maxlen=max_eng_length, padding='post')\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_eng, val_eng, train_fr, val_fr = train_test_split(padded_eng_sequences, padded_fr_sequences, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model using the training data and validate using the validation data\n",
        "model_2.fit(train_eng, to_categorical(train_fr, num_fr_words), batch_size=128, epochs=50, validation_data=(val_eng, to_categorical(val_fr, num_fr_words)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a new function that relies on your new model to make predictions."
      ],
      "metadata": {
        "id": "CkpOI2JI0GBx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Gulu8OiXTbae"
      },
      "outputs": [],
      "source": [
        "#Test Your Zaka\n",
        "def translate_to_french_2(input_sentence):\n",
        "    # Convert the input sentence to a sequence of integers using the English tokenizer\n",
        "    input_seq = eng_tokenizer.texts_to_sequences([input_sentence])[0]\n",
        "    # Pad the input sequence\n",
        "    input_padded = pad_sequences([input_seq], maxlen=max_eng_length, padding='post')\n",
        "    # Use the trained model to generate the output sequence\n",
        "    output_seq = model_2.predict(input_padded)[0]\n",
        "    # Convert the output sequence to a sequence of integers\n",
        "    output_seq = np.argmax(output_seq, axis=-1)\n",
        "    # Convert the output sequence to a sentence using the French tokenizer\n",
        "    output_sentence = fr_tokenizer.sequences_to_texts([output_seq])[0]\n",
        "    # Remove the padding token and any other unwanted characters from the output sentence\n",
        "    output_sentence = output_sentence.replace('<pad>', '').replace(' <eos>', '').strip()\n",
        "    return output_sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"she is driving the truck\"\n",
        "\n",
        "#Test Your Zaka\n",
        "predicted_french_sentence = translate_to_french_2(input)\n",
        "print(input + ' : \\n' +predicted_french_sentence)  "
      ],
      "metadata": {
        "id": "8CO0pO6-UAeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04e94d2-edf8-4afc-aeeb-55b195ba8584"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "she is driving the truck : \n",
            "elle conduit le nouveau camion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is another adjustment in terms of architecture that you might be able to do to improve your model?**"
      ],
      "metadata": {
        "id": "YGeXrjqbZen7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Share Your Zaka]"
      ],
      "metadata": {
        "id": "bekjOkjbZlBf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What are some additional ways that we can do to improve the performance of our model?**"
      ],
      "metadata": {
        "id": "pnIN2lD2tn05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Share Your Zaka]"
      ],
      "metadata": {
        "id": "s7_MCCbQt3uq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_cA93K-TUbcR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}